{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_loader import Loader\n",
    "from src.models.train_model import train_model\n",
    "from models.baseline_model import CIFAR10_Net\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss 2.313925 [   10/50000]\n",
      "loss 2.299000 [ 1010/50000]\n",
      "loss 2.245249 [ 2010/50000]\n",
      "loss 2.193438 [ 3010/50000]\n",
      "loss 2.400093 [ 4010/50000]\n",
      "loss 1.514172 [ 5010/50000]\n",
      "loss 2.041857 [ 6010/50000]\n",
      "loss 1.633690 [ 7010/50000]\n",
      "loss 2.143992 [ 8010/50000]\n",
      "loss 1.828321 [ 9010/50000]\n",
      "loss 1.879997 [10010/50000]\n",
      "loss 1.820648 [11010/50000]\n",
      "loss 1.437497 [12010/50000]\n",
      "loss 1.340838 [13010/50000]\n",
      "loss 1.784105 [14010/50000]\n",
      "loss 1.387907 [15010/50000]\n",
      "loss 1.783966 [16010/50000]\n",
      "loss 1.779204 [17010/50000]\n",
      "loss 2.192767 [18010/50000]\n",
      "loss 1.254840 [19010/50000]\n",
      "loss 1.516801 [20010/50000]\n",
      "loss 1.963326 [21010/50000]\n",
      "loss 1.241560 [22010/50000]\n",
      "loss 1.854357 [23010/50000]\n",
      "loss 1.871575 [24010/50000]\n",
      "loss 1.657100 [25010/50000]\n",
      "loss 1.823002 [26010/50000]\n",
      "loss 1.374341 [27010/50000]\n",
      "loss 1.321328 [28010/50000]\n",
      "loss 1.943353 [29010/50000]\n",
      "loss 1.603797 [30010/50000]\n",
      "loss 1.511310 [31010/50000]\n",
      "loss 1.533537 [32010/50000]\n",
      "loss 1.457728 [33010/50000]\n",
      "loss 1.161242 [34010/50000]\n",
      "loss 2.131263 [35010/50000]\n",
      "loss 2.507757 [36010/50000]\n",
      "loss 1.677621 [37010/50000]\n",
      "loss 1.608166 [38010/50000]\n",
      "loss 0.862594 [39010/50000]\n",
      "loss 1.289264 [40010/50000]\n",
      "loss 1.867711 [41010/50000]\n",
      "loss 1.188839 [42010/50000]\n",
      "loss 1.534661 [43010/50000]\n",
      "loss 1.714430 [44010/50000]\n",
      "loss 1.237443 [45010/50000]\n",
      "loss 1.172284 [46010/50000]\n",
      "loss 2.002164 [47010/50000]\n",
      "loss 1.161212 [48010/50000]\n",
      "loss 1.574926 [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 1.333668 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss 1.539590 [   10/50000]\n",
      "loss 1.005270 [ 1010/50000]\n",
      "loss 1.225626 [ 2010/50000]\n",
      "loss 1.405526 [ 3010/50000]\n",
      "loss 1.282913 [ 4010/50000]\n",
      "loss 1.133593 [ 5010/50000]\n",
      "loss 1.681028 [ 6010/50000]\n",
      "loss 1.375269 [ 7010/50000]\n",
      "loss 2.143967 [ 8010/50000]\n",
      "loss 1.055417 [ 9010/50000]\n",
      "loss 1.186255 [10010/50000]\n",
      "loss 1.289132 [11010/50000]\n",
      "loss 0.804223 [12010/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/CIFAR10/CIFAR10/nootebooks/0.2-test-module.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.147.18.215/CIFAR10/CIFAR10/nootebooks/0.2-test-module.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m train_obj \u001b[39m=\u001b[39m train_model(cifar_model,torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss(),torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(cifar_model\u001b[39m.\u001b[39mparameters(),lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,momentum\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m),device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.147.18.215/CIFAR10/CIFAR10/nootebooks/0.2-test-module.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m ld_obj\u001b[39m.\u001b[39mallocate_mem()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.147.18.215/CIFAR10/CIFAR10/nootebooks/0.2-test-module.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m train_obj\u001b[39m.\u001b[39;49mfit(train_loader,test_loader,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.147.18.215/CIFAR10/CIFAR10/nootebooks/0.2-test-module.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(Loader\u001b[39m.\u001b[39mget_classes())\n",
      "File \u001b[0;32m/CIFAR10/CIFAR10/src/models/train_model.py:67\u001b[0m, in \u001b[0;36mtrain_model.fit\u001b[0;34m(self, trainloader, testloader, epochs, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     66\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(trainloader, verbose)\n\u001b[1;32m     68\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest(testloader, verbose)\n\u001b[1;32m     69\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/CIFAR10/CIFAR10/src/models/train_model.py:22\u001b[0m, in \u001b[0;36mtrain_model.train\u001b[0;34m(self, trainloader, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     18\u001b[0m           trainloader:torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mdataloader\u001b[39m.\u001b[39mDataLoader,\n\u001b[1;32m     19\u001b[0m           verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(trainloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfor\u001b[39;00m i,data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[1;32m     23\u001b[0m         inputs,target \u001b[39m=\u001b[39m data\n\u001b[1;32m     24\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/site-packages/torch/multiprocessing/reductions.py:355\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrebuild_storage_fd\u001b[39m(\u001b[39mcls\u001b[39m, df, size):\n\u001b[0;32m--> 355\u001b[0m     fd \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m    356\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    357\u001b[0m         storage \u001b[39m=\u001b[39m storage_from_cache(\u001b[39mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/multiprocessing/resource_sharer.py:57\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetach\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     56\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mwith\u001b[39;00m _resource_sharer\u001b[39m.\u001b[39;49mget_connection(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id) \u001b[39mas\u001b[39;00m conn:\n\u001b[1;32m     58\u001b[0m         \u001b[39mreturn\u001b[39;00m reduction\u001b[39m.\u001b[39mrecv_handle(conn)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/multiprocessing/resource_sharer.py:86\u001b[0m, in \u001b[0;36m_ResourceSharer.get_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m Client\n\u001b[1;32m     85\u001b[0m address, key \u001b[39m=\u001b[39m ident\n\u001b[0;32m---> 86\u001b[0m c \u001b[39m=\u001b[39m Client(address, authkey\u001b[39m=\u001b[39;49mprocess\u001b[39m.\u001b[39;49mcurrent_process()\u001b[39m.\u001b[39;49mauthkey)\n\u001b[1;32m     87\u001b[0m c\u001b[39m.\u001b[39msend((key, os\u001b[39m.\u001b[39mgetpid()))\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/multiprocessing/connection.py:502\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    500\u001b[0m     c \u001b[39m=\u001b[39m PipeClient(address)\n\u001b[1;32m    501\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     c \u001b[39m=\u001b[39m SocketClient(address)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m authkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(authkey, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m    505\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mauthkey should be a byte string\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.10/multiprocessing/connection.py:630\u001b[0m, in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mwith\u001b[39;00m socket\u001b[39m.\u001b[39msocket( \u001b[39mgetattr\u001b[39m(socket, family) ) \u001b[39mas\u001b[39;00m s:\n\u001b[1;32m    629\u001b[0m     s\u001b[39m.\u001b[39msetblocking(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 630\u001b[0m     s\u001b[39m.\u001b[39;49mconnect(address)\n\u001b[1;32m    631\u001b[0m     \u001b[39mreturn\u001b[39;00m Connection(s\u001b[39m.\u001b[39mdetach())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cifar_model = CIFAR10_Net().to(\"cuda\")\n",
    "\n",
    "ld_obj = Loader(device=\"cuda\")\n",
    "\n",
    "train_loader = ld_obj.load_train(root=\"../data/raw\",batch_size=10)\n",
    "test_loader = ld_obj.load_test(root=\"../data/raw\",batch_size=10)\n",
    "\n",
    "train_obj = train_model(cifar_model,torch.nn.CrossEntropyLoss(),torch.optim.SGD(cifar_model.parameters(),lr=0.01,momentum=0.8),device=\"cuda\")\n",
    "ld_obj.allocate_mem()\n",
    "train_obj.fit(train_loader,test_loader,epochs=10,verbose=True)\n",
    "\n",
    "print(Loader.get_classes())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
